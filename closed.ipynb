{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo_CLOSED.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDqOmq90L4gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cde07cf3-d71b-4383-cbec-3aa4890ee5b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9N3byrWtFqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/My Drive/Trabajo/Airline'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmQA4puVKZS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_FILES = [\n",
        "  '/content/drive/My Drive/WX6040.csv'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhH800ErtpzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MONTHS = ['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre']\n",
        "\n",
        "def encoding_month(month):\n",
        "  return MONTHS.index(month) + 1\n",
        "\n",
        "def encoding_hour(hour):\n",
        "  hour_nums = hour.split(':')\n",
        "  assert(len(hour_nums) == 3)\n",
        "  nhour = int(hour_nums[0]) + (int(hour_nums[1]) / 60) + (int(hour_nums[2]) / 3600)\n",
        "  return nhour\n",
        "\n",
        "def encoding_day(date):\n",
        "    for fmt in ('%Y-%m-%d %M:%S:%f', '%d/%m/%Y %H:%M', '%d/%m/%Y'):\n",
        "        try:\n",
        "            return datetime.strptime(date, fmt).day\n",
        "        except ValueError:\n",
        "            pass\n",
        "    raise ValueError('No valid date format found: {}'.format(date))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JynCOahczaL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequences(a, width=3, offset=0, limit=0):\n",
        "    n = a.shape[0]\n",
        "    result = []\n",
        "    for i in range(offset, n - width + limit):\n",
        "      result.append(a[i: i+width])\n",
        "      \n",
        "    return np.asarray(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0UTmhXauPUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURES = 7\n",
        "SAMPLES = 24\n",
        "PREDICTIONS = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hdG1x5xJ1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "f6433e1c-b58e-4900-9caf-98fd48085e54"
      },
      "source": [
        "x_data = None\n",
        "y_data = None\n",
        "\n",
        "for idx, dataset_file in enumerate(DATASET_FILES):\n",
        "  \n",
        "  print('----------------------------------------------------------------')\n",
        "  print('Iteration {} File {}'.format(idx, dataset_file))\n",
        "  \n",
        "  df = pd.read_csv(dataset_file)\n",
        "  df = df[['DATE', 'ANIO', 'MES', 'HORA','VISIBILIDAD', 'GRADOS', 'INTENSIDAD', 'TEMPERATURA', 'PUNTO_ROCIO', 'CLOSED']]\n",
        "  df['MES_ENC'] = df['MES'].apply(lambda x: encoding_month(x))\n",
        "  df['DIA_ENC'] = df['DATE'].apply(lambda x: encoding_day(x))\n",
        "  df['HORA_ENC'] = df['HORA'].apply(lambda x: encoding_hour(x))\n",
        "\n",
        "  # [['MES_ENC', 'DIA_ENC', 'HORA_ENC', 'GRADOS', 'INTENSIDAD', 'TEMPERATURA', 'PUNTO_ROCIO', 'VISIBILIDAD']] \\\n",
        "  df = df.sort_values(by=['ANIO', 'MES_ENC', 'DIA_ENC', 'HORA_ENC'], ascending=True) \\\n",
        "            [['MES_ENC', 'HORA_ENC','VISIBILIDAD',  'GRADOS', 'INTENSIDAD','TEMPERATURA', 'PUNTO_ROCIO', 'CLOSED']] \\\n",
        "            .interpolate()\n",
        "\n",
        "\n",
        "  x = df.drop(['CLOSED'], axis=1)\n",
        "  y = df[['CLOSED']]\n",
        "\n",
        "  x = x.values\n",
        "  y = y.values\n",
        "\n",
        "  print('X-Shape:{} \\t Y-Shape:{}'.format(x.shape, y.shape))\n",
        "\n",
        "  y_nan_indices = np.argwhere(np.isnan(y))\n",
        "  print('File {}     Y     Nan {}'.format(idx, y_nan_indices.shape))\n",
        "  \n",
        "  for i in range(FEATURES):\n",
        "    x_nan_indices = np.argwhere(np.isnan(x[:, i]))\n",
        "    print('File {}     Feature {}    Nan {}'.format(idx, i, x_nan_indices.shape))\n",
        "\n",
        "\n",
        "\n",
        "  if x_data is None:\n",
        "    x_data = sequences(x, width=SAMPLES, limit=-PREDICTIONS)\n",
        "    y_data = sequences(y, offset=SAMPLES, width=PREDICTIONS)\n",
        "  else:\n",
        "    x_data = np.concatenate([x_data, sequences(x, width=SAMPLES, limit=-PREDICTIONS)], axis=0)\n",
        "    y_data = np.concatenate([y_data, sequences(y, offset=SAMPLES, width=PREDICTIONS)], axis=0)\n",
        "\n",
        "#y_data = y_data.reshape(y_data.shape[0], 1)\n",
        "print('----------------------------------------------------------------')\n",
        "print('Total')\n",
        "print('X-Shape:{} \\t Y-Shape:{}'.format(x_data.shape, y_data.shape))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "Iteration 0 File /content/drive/My Drive/WX6040.csv\n",
            "X-Shape:(27497, 7) \t Y-Shape:(27497, 1)\n",
            "File 0     Y     Nan (0, 2)\n",
            "File 0     Feature 0    Nan (0, 1)\n",
            "File 0     Feature 1    Nan (0, 1)\n",
            "File 0     Feature 2    Nan (0, 1)\n",
            "File 0     Feature 3    Nan (0, 1)\n",
            "File 0     Feature 4    Nan (0, 1)\n",
            "File 0     Feature 5    Nan (0, 1)\n",
            "File 0     Feature 6    Nan (0, 1)\n",
            "----------------------------------------------------------------\n",
            "Total\n",
            "X-Shape:(27465, 24, 7) \t Y-Shape:(27465, 8, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixAptiRmJMIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4d2726cc-556b-4fef-8039-9388a7ec5647"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MES_ENC</th>\n",
              "      <th>HORA_ENC</th>\n",
              "      <th>VISIBILIDAD</th>\n",
              "      <th>GRADOS</th>\n",
              "      <th>INTENSIDAD</th>\n",
              "      <th>TEMPERATURA</th>\n",
              "      <th>PUNTO_ROCIO</th>\n",
              "      <th>CLOSED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>180</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>170</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.37</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>160</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MES_ENC  HORA_ENC  VISIBILIDAD  ...  TEMPERATURA  PUNTO_ROCIO  CLOSED\n",
              "0        1      11.0         0.50  ...           19           19       1\n",
              "1        1      12.0         0.50  ...           19           19       1\n",
              "2        1      13.0         0.37  ...           19           19       1\n",
              "3        1      14.0         0.62  ...           19           19       1\n",
              "4        1      11.0         0.00  ...           19           19       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izLvMvlQBfUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "\n",
        "    x = keras.layers.Input(shape=(SAMPLES, FEATURES))\n",
        "    \n",
        "    out = x\n",
        "\n",
        "    out = keras.layers.GRU(512,\n",
        "                           activation='relu',\n",
        "                           dropout=0.2, \n",
        "                           recurrent_dropout=0.1,\n",
        "                           return_sequences=True\n",
        "                           #kernel_regularizer=keras.regularizers.l2(0.01), \n",
        "                           #recurrent_regularizer=keras.regularizers.l2(0.01), \n",
        "                           #bias_regularizer=keras.regularizers.l2(0.01)\n",
        "                          )(out)\n",
        "\n",
        "    out = keras.layers.Lambda(lambda x: x[:, -PREDICTIONS:])(out)\n",
        "\n",
        "    out = keras.layers.TimeDistributed(keras.layers.Dense(128))(out)\n",
        "    out = keras.layers.BatchNormalization()(out)\n",
        "    out = keras.layers.ReLU()(out)\n",
        "    out = keras.layers.Dropout(0.2)(out)\n",
        "    \n",
        "    out = keras.layers.Dense(64)(out)\n",
        "    out = keras.layers.BatchNormalization()(out)\n",
        "    out = keras.layers.ReLU()(out)\n",
        "    out = keras.layers.Dropout(0.1)(out)\n",
        "    \n",
        "    out = keras.layers.Dense(16)(out)\n",
        "    out = keras.layers.BatchNormalization()(out)\n",
        "    out = keras.layers.ReLU()(out)\n",
        "    \n",
        "    out = keras.layers.Dense(1)(out)\n",
        "    out = keras.layers.Activation('sigmoid')(out)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[x], outputs=[out])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx5r4iQADo5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "f155d5f9-5ad0-42ec-ab24-8bc17edbad4f"
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 24, 7)             0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 24, 512)           798720    \n",
            "_________________________________________________________________\n",
            "lambda_3 (Lambda)            (None, 8, 512)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 8, 128)            65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 128)            512       \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8, 64)             8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 8, 64)             256       \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 8, 64)             0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 64)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 8, 16)             1040      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 16)             64        \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 8, 16)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8, 1)              17        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 1)              0         \n",
            "=================================================================\n",
            "Total params: 874,529\n",
            "Trainable params: 874,113\n",
            "Non-trainable params: 416\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5eD26n1NQAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-3\n",
        "EARLY_STOPPING_LIMIT = 60\n",
        "LR_REDUCE_LIMIT = 40\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE = 1024\n",
        "TEST_SIZE = 0.2\n",
        "DEV_SIZE = 0.2\n",
        "\n",
        "MODEL_FILE = 'closed_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dza8NWC4N73W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=TEST_SIZE, random_state=42)\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=DEV_SIZE, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TuGA9R8xjly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape(x, oshape):\n",
        "  return x.reshape((oshape[0] * oshape[1], oshape[2]))\n",
        "\n",
        "def ireshape(x, oshape):\n",
        "  return x.reshape(oshape)\n",
        "\n",
        "otshape = x_train.shape\n",
        "odshape = x_dev.shape\n",
        "ottshape = x_test.shape\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(reshape(x_train, otshape))\n",
        "\n",
        "with open('closed.scaler', 'wb') as visibility_file:\n",
        "  pickle.dump(scaler, visibility_file)\n",
        "\n",
        "x_train = ireshape(scaler.transform(reshape(x_train, otshape)), otshape)\n",
        "x_test = ireshape(scaler.transform(reshape(x_test, ottshape)), ottshape)\n",
        "x_dev = ireshape(scaler.transform(reshape(x_dev, odshape)), odshape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdueq54bMmGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a61ab0cc-c463-4605-897b-76e6f727bd6b"
      },
      "source": [
        "model = get_model()\n",
        "loss_fn = keras.losses.binary_crossentropy\n",
        "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE, amsgrad=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=EARLY_STOPPING_LIMIT, \n",
        "    min_delta=1e-4, \n",
        "    restore_best_weights=True, \n",
        "    monitor='val_loss',\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "stop_nan = keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "save_weights = keras.callbacks.ModelCheckpoint(\n",
        "    MODEL_FILE, \n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', \n",
        "    factor=0.1, \n",
        "    patience=LR_REDUCE_LIMIT, \n",
        "    verbose=1,\n",
        "    min_delta=1e-4, \n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    epochs=EPOCHS, \n",
        "    callbacks=[early_stopping, stop_nan, save_weights, reduce_lr_loss], \n",
        "    validation_data=[x_dev, y_dev], \n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17577 samples, validate on 4395 samples\n",
            "Epoch 1/500\n",
            "17577/17577 [==============================] - 2s 142us/step - loss: 0.6705 - accuracy: 0.6084 - val_loss: 0.6764 - val_accuracy: 0.6301\n",
            "Epoch 2/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.6376 - accuracy: 0.6391 - val_loss: 0.6663 - val_accuracy: 0.6113\n",
            "Epoch 3/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.6306 - accuracy: 0.6451 - val_loss: 0.6585 - val_accuracy: 0.6093\n",
            "Epoch 4/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.6283 - accuracy: 0.6462 - val_loss: 0.6576 - val_accuracy: 0.6076\n",
            "Epoch 5/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.6257 - accuracy: 0.6510 - val_loss: 0.6579 - val_accuracy: 0.6064\n",
            "Epoch 6/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.6256 - accuracy: 0.6494 - val_loss: 0.6545 - val_accuracy: 0.6049\n",
            "Epoch 7/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.6213 - accuracy: 0.6539 - val_loss: 0.6523 - val_accuracy: 0.6073\n",
            "Epoch 8/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.6203 - accuracy: 0.6539 - val_loss: 0.6489 - val_accuracy: 0.6102\n",
            "Epoch 9/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.6189 - accuracy: 0.6548 - val_loss: 0.6479 - val_accuracy: 0.6106\n",
            "Epoch 10/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.6169 - accuracy: 0.6567 - val_loss: 0.6456 - val_accuracy: 0.6177\n",
            "Epoch 11/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.6143 - accuracy: 0.6597 - val_loss: 0.6439 - val_accuracy: 0.6138\n",
            "Epoch 12/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.6118 - accuracy: 0.6613 - val_loss: 0.6433 - val_accuracy: 0.6143\n",
            "Epoch 13/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.6116 - accuracy: 0.6624 - val_loss: 0.6400 - val_accuracy: 0.6222\n",
            "Epoch 14/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.6086 - accuracy: 0.6648 - val_loss: 0.6375 - val_accuracy: 0.6220\n",
            "Epoch 15/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.6056 - accuracy: 0.6686 - val_loss: 0.6336 - val_accuracy: 0.6307\n",
            "Epoch 16/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.6037 - accuracy: 0.6677 - val_loss: 0.6254 - val_accuracy: 0.6342\n",
            "Epoch 17/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.6003 - accuracy: 0.6737 - val_loss: 0.6240 - val_accuracy: 0.6414\n",
            "Epoch 18/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.5963 - accuracy: 0.6766 - val_loss: 0.6204 - val_accuracy: 0.6437\n",
            "Epoch 19/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.5944 - accuracy: 0.6787 - val_loss: 0.6130 - val_accuracy: 0.6483\n",
            "Epoch 20/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.5937 - accuracy: 0.6799 - val_loss: 0.6125 - val_accuracy: 0.6564\n",
            "Epoch 21/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.5875 - accuracy: 0.6845 - val_loss: 0.6093 - val_accuracy: 0.6607\n",
            "Epoch 22/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.5836 - accuracy: 0.6877 - val_loss: 0.6027 - val_accuracy: 0.6737\n",
            "Epoch 23/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.5803 - accuracy: 0.6916 - val_loss: 0.5906 - val_accuracy: 0.6756\n",
            "Epoch 24/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.5713 - accuracy: 0.6976 - val_loss: 0.5858 - val_accuracy: 0.6831\n",
            "Epoch 25/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.5693 - accuracy: 0.7013 - val_loss: 0.5831 - val_accuracy: 0.6848\n",
            "Epoch 26/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.5642 - accuracy: 0.7043 - val_loss: 0.5735 - val_accuracy: 0.6911\n",
            "Epoch 27/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.5604 - accuracy: 0.7085 - val_loss: 0.5647 - val_accuracy: 0.7064\n",
            "Epoch 28/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.5516 - accuracy: 0.7132 - val_loss: 0.5505 - val_accuracy: 0.7105\n",
            "Epoch 29/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.5466 - accuracy: 0.7176 - val_loss: 0.5564 - val_accuracy: 0.7032\n",
            "Epoch 30/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.5372 - accuracy: 0.7246 - val_loss: 0.5437 - val_accuracy: 0.7129\n",
            "Epoch 31/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.5315 - accuracy: 0.7294 - val_loss: 0.5358 - val_accuracy: 0.7185\n",
            "Epoch 32/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.5249 - accuracy: 0.7333 - val_loss: 0.5204 - val_accuracy: 0.7317\n",
            "Epoch 33/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.5195 - accuracy: 0.7368 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
            "Epoch 34/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.5083 - accuracy: 0.7438 - val_loss: 0.5169 - val_accuracy: 0.7280\n",
            "Epoch 35/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.5021 - accuracy: 0.7490 - val_loss: 0.5053 - val_accuracy: 0.7391\n",
            "Epoch 36/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.4958 - accuracy: 0.7528 - val_loss: 0.4837 - val_accuracy: 0.7651\n",
            "Epoch 37/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.4899 - accuracy: 0.7576 - val_loss: 0.4841 - val_accuracy: 0.7611\n",
            "Epoch 38/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.4879 - accuracy: 0.7573 - val_loss: 0.4717 - val_accuracy: 0.7672\n",
            "Epoch 39/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.4810 - accuracy: 0.7613 - val_loss: 0.4594 - val_accuracy: 0.7839\n",
            "Epoch 40/500\n",
            "17577/17577 [==============================] - 2s 106us/step - loss: 0.4707 - accuracy: 0.7691 - val_loss: 0.4555 - val_accuracy: 0.7836\n",
            "Epoch 41/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.4645 - accuracy: 0.7733 - val_loss: 0.4464 - val_accuracy: 0.7856\n",
            "Epoch 42/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.4563 - accuracy: 0.7788 - val_loss: 0.4284 - val_accuracy: 0.8083\n",
            "Epoch 43/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.4488 - accuracy: 0.7825 - val_loss: 0.4365 - val_accuracy: 0.7882\n",
            "Epoch 44/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.4457 - accuracy: 0.7851 - val_loss: 0.4248 - val_accuracy: 0.8018\n",
            "Epoch 45/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.4338 - accuracy: 0.7927 - val_loss: 0.4124 - val_accuracy: 0.8120\n",
            "Epoch 46/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.4070 - val_accuracy: 0.8139\n",
            "Epoch 47/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.4294 - accuracy: 0.7928 - val_loss: 0.4032 - val_accuracy: 0.8228\n",
            "Epoch 48/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.4214 - accuracy: 0.7996 - val_loss: 0.3969 - val_accuracy: 0.8242\n",
            "Epoch 49/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.4138 - accuracy: 0.8032 - val_loss: 0.3891 - val_accuracy: 0.8263\n",
            "Epoch 50/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.4080 - accuracy: 0.8058 - val_loss: 0.3830 - val_accuracy: 0.8244\n",
            "Epoch 51/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.4042 - accuracy: 0.8084 - val_loss: 0.3708 - val_accuracy: 0.8344\n",
            "Epoch 52/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.4002 - accuracy: 0.8107 - val_loss: 0.3664 - val_accuracy: 0.8416\n",
            "Epoch 53/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.3932 - accuracy: 0.8158 - val_loss: 0.3645 - val_accuracy: 0.8465\n",
            "Epoch 54/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.3867 - accuracy: 0.8189 - val_loss: 0.3588 - val_accuracy: 0.8401\n",
            "Epoch 55/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.3780 - accuracy: 0.8236 - val_loss: 0.3387 - val_accuracy: 0.8617\n",
            "Epoch 56/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.3772 - accuracy: 0.8233 - val_loss: 0.3390 - val_accuracy: 0.8558\n",
            "Epoch 57/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.3743 - accuracy: 0.8246 - val_loss: 0.3254 - val_accuracy: 0.8680\n",
            "Epoch 58/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3665 - accuracy: 0.8298 - val_loss: 0.3183 - val_accuracy: 0.8690\n",
            "Epoch 59/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.3631 - accuracy: 0.8311 - val_loss: 0.3151 - val_accuracy: 0.8734\n",
            "Epoch 60/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3566 - accuracy: 0.8346 - val_loss: 0.3182 - val_accuracy: 0.8722\n",
            "Epoch 61/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.3546 - accuracy: 0.8353 - val_loss: 0.3033 - val_accuracy: 0.8788\n",
            "Epoch 62/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.3501 - accuracy: 0.8395 - val_loss: 0.3038 - val_accuracy: 0.8771\n",
            "Epoch 63/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3473 - accuracy: 0.8397 - val_loss: 0.2961 - val_accuracy: 0.8806\n",
            "Epoch 64/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3376 - accuracy: 0.8432 - val_loss: 0.2974 - val_accuracy: 0.8833\n",
            "Epoch 65/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.3365 - accuracy: 0.8453 - val_loss: 0.2789 - val_accuracy: 0.8917\n",
            "Epoch 66/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.3340 - accuracy: 0.8459 - val_loss: 0.2820 - val_accuracy: 0.8912\n",
            "Epoch 67/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.3296 - accuracy: 0.8486 - val_loss: 0.2711 - val_accuracy: 0.8946\n",
            "Epoch 68/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.3241 - accuracy: 0.8514 - val_loss: 0.2708 - val_accuracy: 0.8956\n",
            "Epoch 69/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3194 - accuracy: 0.8544 - val_loss: 0.2624 - val_accuracy: 0.9000\n",
            "Epoch 70/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3148 - accuracy: 0.8555 - val_loss: 0.2686 - val_accuracy: 0.8964\n",
            "Epoch 71/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.3128 - accuracy: 0.8564 - val_loss: 0.2666 - val_accuracy: 0.8966\n",
            "Epoch 72/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.3085 - accuracy: 0.8583 - val_loss: 0.2745 - val_accuracy: 0.8876\n",
            "Epoch 73/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.3043 - accuracy: 0.8623 - val_loss: 0.2493 - val_accuracy: 0.9065\n",
            "Epoch 74/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.3061 - accuracy: 0.8603 - val_loss: 0.2543 - val_accuracy: 0.9053\n",
            "Epoch 75/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.2949 - accuracy: 0.8674 - val_loss: 0.2458 - val_accuracy: 0.9141\n",
            "Epoch 76/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.2942 - accuracy: 0.8656 - val_loss: 0.2418 - val_accuracy: 0.9083\n",
            "Epoch 77/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2931 - accuracy: 0.8668 - val_loss: 0.2395 - val_accuracy: 0.9122\n",
            "Epoch 78/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2900 - accuracy: 0.8673 - val_loss: 0.2284 - val_accuracy: 0.9194\n",
            "Epoch 79/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.2868 - accuracy: 0.8695 - val_loss: 0.2345 - val_accuracy: 0.9129\n",
            "Epoch 80/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.2870 - accuracy: 0.8698 - val_loss: 0.2354 - val_accuracy: 0.9150\n",
            "Epoch 81/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.2805 - accuracy: 0.8719 - val_loss: 0.2211 - val_accuracy: 0.9219\n",
            "Epoch 82/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2770 - accuracy: 0.8760 - val_loss: 0.2241 - val_accuracy: 0.9199\n",
            "Epoch 83/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2732 - accuracy: 0.8774 - val_loss: 0.2199 - val_accuracy: 0.9242\n",
            "Epoch 84/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.2706 - accuracy: 0.8777 - val_loss: 0.2200 - val_accuracy: 0.9268\n",
            "Epoch 85/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2702 - accuracy: 0.8784 - val_loss: 0.2207 - val_accuracy: 0.9168\n",
            "Epoch 86/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2660 - accuracy: 0.8805 - val_loss: 0.2135 - val_accuracy: 0.9223\n",
            "Epoch 87/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.2621 - accuracy: 0.8829 - val_loss: 0.2086 - val_accuracy: 0.9286\n",
            "Epoch 88/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.2618 - accuracy: 0.8821 - val_loss: 0.2082 - val_accuracy: 0.9280\n",
            "Epoch 89/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2570 - accuracy: 0.8848 - val_loss: 0.2033 - val_accuracy: 0.9280\n",
            "Epoch 90/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2596 - accuracy: 0.8843 - val_loss: 0.2003 - val_accuracy: 0.9321\n",
            "Epoch 91/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2511 - accuracy: 0.8881 - val_loss: 0.1984 - val_accuracy: 0.9278\n",
            "Epoch 92/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.2518 - accuracy: 0.8877 - val_loss: 0.1973 - val_accuracy: 0.9323\n",
            "Epoch 93/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.2462 - accuracy: 0.8911 - val_loss: 0.1989 - val_accuracy: 0.9286\n",
            "Epoch 94/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2456 - accuracy: 0.8904 - val_loss: 0.1851 - val_accuracy: 0.9388\n",
            "Epoch 95/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2414 - accuracy: 0.8928 - val_loss: 0.1898 - val_accuracy: 0.9354\n",
            "Epoch 96/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.2421 - accuracy: 0.8925 - val_loss: 0.1931 - val_accuracy: 0.9322\n",
            "Epoch 97/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2356 - accuracy: 0.8958 - val_loss: 0.1851 - val_accuracy: 0.9402\n",
            "Epoch 98/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2385 - accuracy: 0.8943 - val_loss: 0.1774 - val_accuracy: 0.9453\n",
            "Epoch 99/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.2343 - accuracy: 0.8963 - val_loss: 0.1730 - val_accuracy: 0.9430\n",
            "Epoch 100/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2331 - accuracy: 0.8971 - val_loss: 0.1734 - val_accuracy: 0.9449\n",
            "Epoch 101/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.2322 - accuracy: 0.8972 - val_loss: 0.1740 - val_accuracy: 0.9403\n",
            "Epoch 102/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2310 - accuracy: 0.8977 - val_loss: 0.1713 - val_accuracy: 0.9409\n",
            "Epoch 103/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2296 - accuracy: 0.8983 - val_loss: 0.1712 - val_accuracy: 0.9457\n",
            "Epoch 104/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2294 - accuracy: 0.8980 - val_loss: 0.1652 - val_accuracy: 0.9489\n",
            "Epoch 105/500\n",
            "17577/17577 [==============================] - 2s 100us/step - loss: 0.2268 - accuracy: 0.8985 - val_loss: 0.1693 - val_accuracy: 0.9478\n",
            "Epoch 106/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.2228 - accuracy: 0.9014 - val_loss: 0.1628 - val_accuracy: 0.9512\n",
            "Epoch 107/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.2187 - accuracy: 0.9039 - val_loss: 0.1638 - val_accuracy: 0.9488\n",
            "Epoch 108/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.2200 - accuracy: 0.9035 - val_loss: 0.1678 - val_accuracy: 0.9456\n",
            "Epoch 109/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.2155 - accuracy: 0.9053 - val_loss: 0.1609 - val_accuracy: 0.9483\n",
            "Epoch 110/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.2202 - accuracy: 0.9024 - val_loss: 0.1577 - val_accuracy: 0.9486\n",
            "Epoch 111/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2152 - accuracy: 0.9053 - val_loss: 0.1514 - val_accuracy: 0.9530\n",
            "Epoch 112/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2139 - accuracy: 0.9052 - val_loss: 0.1505 - val_accuracy: 0.9565\n",
            "Epoch 113/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.2108 - accuracy: 0.9075 - val_loss: 0.1518 - val_accuracy: 0.9509\n",
            "Epoch 114/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.2056 - accuracy: 0.9101 - val_loss: 0.1478 - val_accuracy: 0.9554\n",
            "Epoch 115/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.2070 - accuracy: 0.9093 - val_loss: 0.1465 - val_accuracy: 0.9554\n",
            "Epoch 116/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.2029 - accuracy: 0.9109 - val_loss: 0.1441 - val_accuracy: 0.9588\n",
            "Epoch 117/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.2069 - accuracy: 0.9082 - val_loss: 0.1440 - val_accuracy: 0.9599\n",
            "Epoch 118/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2048 - accuracy: 0.9103 - val_loss: 0.1517 - val_accuracy: 0.9522\n",
            "Epoch 119/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.2010 - accuracy: 0.9115 - val_loss: 0.1387 - val_accuracy: 0.9590\n",
            "Epoch 120/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1992 - accuracy: 0.9129 - val_loss: 0.1348 - val_accuracy: 0.9605\n",
            "Epoch 121/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.2008 - accuracy: 0.9120 - val_loss: 0.1329 - val_accuracy: 0.9618\n",
            "Epoch 122/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1985 - accuracy: 0.9132 - val_loss: 0.1300 - val_accuracy: 0.9629\n",
            "Epoch 123/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1983 - accuracy: 0.9136 - val_loss: 0.1318 - val_accuracy: 0.9623\n",
            "Epoch 124/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1929 - accuracy: 0.9166 - val_loss: 0.1336 - val_accuracy: 0.9623\n",
            "Epoch 125/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1945 - accuracy: 0.9157 - val_loss: 0.1354 - val_accuracy: 0.9609\n",
            "Epoch 126/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1946 - accuracy: 0.9154 - val_loss: 0.1315 - val_accuracy: 0.9608\n",
            "Epoch 127/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1931 - accuracy: 0.9147 - val_loss: 0.1288 - val_accuracy: 0.9647\n",
            "Epoch 128/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1896 - accuracy: 0.9175 - val_loss: 0.1286 - val_accuracy: 0.9625\n",
            "Epoch 129/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1905 - accuracy: 0.9172 - val_loss: 0.1308 - val_accuracy: 0.9609\n",
            "Epoch 130/500\n",
            "17577/17577 [==============================] - 1s 85us/step - loss: 0.1875 - accuracy: 0.9175 - val_loss: 0.1245 - val_accuracy: 0.9649\n",
            "Epoch 131/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1891 - accuracy: 0.9175 - val_loss: 0.1249 - val_accuracy: 0.9635\n",
            "Epoch 132/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1860 - accuracy: 0.9199 - val_loss: 0.1235 - val_accuracy: 0.9624\n",
            "Epoch 133/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1856 - accuracy: 0.9189 - val_loss: 0.1178 - val_accuracy: 0.9657\n",
            "Epoch 134/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1846 - accuracy: 0.9203 - val_loss: 0.1191 - val_accuracy: 0.9676\n",
            "Epoch 135/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1803 - accuracy: 0.9218 - val_loss: 0.1212 - val_accuracy: 0.9682\n",
            "Epoch 136/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1811 - accuracy: 0.9219 - val_loss: 0.1201 - val_accuracy: 0.9678\n",
            "Epoch 137/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1806 - accuracy: 0.9219 - val_loss: 0.1145 - val_accuracy: 0.9687\n",
            "Epoch 138/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1807 - accuracy: 0.9215 - val_loss: 0.1119 - val_accuracy: 0.9697\n",
            "Epoch 139/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1766 - accuracy: 0.9239 - val_loss: 0.1189 - val_accuracy: 0.9675\n",
            "Epoch 140/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1752 - accuracy: 0.9248 - val_loss: 0.1162 - val_accuracy: 0.9664\n",
            "Epoch 141/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1760 - accuracy: 0.9237 - val_loss: 0.1146 - val_accuracy: 0.9689\n",
            "Epoch 142/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1779 - accuracy: 0.9230 - val_loss: 0.1194 - val_accuracy: 0.9689\n",
            "Epoch 143/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1727 - accuracy: 0.9262 - val_loss: 0.1164 - val_accuracy: 0.9683\n",
            "Epoch 144/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1751 - accuracy: 0.9244 - val_loss: 0.1263 - val_accuracy: 0.9591\n",
            "Epoch 145/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1738 - accuracy: 0.9251 - val_loss: 0.1137 - val_accuracy: 0.9677\n",
            "Epoch 146/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1722 - accuracy: 0.9255 - val_loss: 0.1094 - val_accuracy: 0.9712\n",
            "Epoch 147/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1681 - accuracy: 0.9279 - val_loss: 0.1103 - val_accuracy: 0.9711\n",
            "Epoch 148/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1683 - accuracy: 0.9278 - val_loss: 0.1032 - val_accuracy: 0.9722\n",
            "Epoch 149/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1678 - accuracy: 0.9282 - val_loss: 0.1076 - val_accuracy: 0.9700\n",
            "Epoch 150/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1678 - accuracy: 0.9275 - val_loss: 0.1095 - val_accuracy: 0.9667\n",
            "Epoch 151/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1698 - accuracy: 0.9265 - val_loss: 0.1082 - val_accuracy: 0.9714\n",
            "Epoch 152/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1628 - accuracy: 0.9297 - val_loss: 0.1103 - val_accuracy: 0.9669\n",
            "Epoch 153/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1671 - accuracy: 0.9280 - val_loss: 0.1028 - val_accuracy: 0.9726\n",
            "Epoch 154/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1640 - accuracy: 0.9286 - val_loss: 0.1001 - val_accuracy: 0.9716\n",
            "Epoch 155/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.1646 - accuracy: 0.9295 - val_loss: 0.0973 - val_accuracy: 0.9738\n",
            "Epoch 156/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1613 - accuracy: 0.9310 - val_loss: 0.0996 - val_accuracy: 0.9747\n",
            "Epoch 157/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1618 - accuracy: 0.9306 - val_loss: 0.0968 - val_accuracy: 0.9758\n",
            "Epoch 158/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1608 - accuracy: 0.9309 - val_loss: 0.0961 - val_accuracy: 0.9755\n",
            "Epoch 159/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1600 - accuracy: 0.9311 - val_loss: 0.0955 - val_accuracy: 0.9773\n",
            "Epoch 160/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1602 - accuracy: 0.9314 - val_loss: 0.0924 - val_accuracy: 0.9767\n",
            "Epoch 161/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1564 - accuracy: 0.9324 - val_loss: 0.1000 - val_accuracy: 0.9730\n",
            "Epoch 162/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1531 - accuracy: 0.9346 - val_loss: 0.0937 - val_accuracy: 0.9761\n",
            "Epoch 163/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1567 - accuracy: 0.9329 - val_loss: 0.0928 - val_accuracy: 0.9761\n",
            "Epoch 164/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1528 - accuracy: 0.9341 - val_loss: 0.0868 - val_accuracy: 0.9776\n",
            "Epoch 165/500\n",
            "17577/17577 [==============================] - 2s 101us/step - loss: 0.1545 - accuracy: 0.9337 - val_loss: 0.0962 - val_accuracy: 0.9748\n",
            "Epoch 166/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1525 - accuracy: 0.9346 - val_loss: 0.0906 - val_accuracy: 0.9779\n",
            "Epoch 167/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1565 - accuracy: 0.9332 - val_loss: 0.0846 - val_accuracy: 0.9792\n",
            "Epoch 168/500\n",
            "17577/17577 [==============================] - 2s 102us/step - loss: 0.1556 - accuracy: 0.9340 - val_loss: 0.0949 - val_accuracy: 0.9744\n",
            "Epoch 169/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1566 - accuracy: 0.9327 - val_loss: 0.0902 - val_accuracy: 0.9768\n",
            "Epoch 170/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1520 - accuracy: 0.9355 - val_loss: 0.0894 - val_accuracy: 0.9771\n",
            "Epoch 171/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.1534 - accuracy: 0.9343 - val_loss: 0.0864 - val_accuracy: 0.9788\n",
            "Epoch 172/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1499 - accuracy: 0.9359 - val_loss: 0.0896 - val_accuracy: 0.9777\n",
            "Epoch 173/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1516 - accuracy: 0.9351 - val_loss: 0.0854 - val_accuracy: 0.9780\n",
            "Epoch 174/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1482 - accuracy: 0.9371 - val_loss: 0.0886 - val_accuracy: 0.9790\n",
            "Epoch 175/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1513 - accuracy: 0.9347 - val_loss: 0.0834 - val_accuracy: 0.9796\n",
            "Epoch 176/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1485 - accuracy: 0.9365 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
            "Epoch 177/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1466 - accuracy: 0.9370 - val_loss: 0.0820 - val_accuracy: 0.9784\n",
            "Epoch 178/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1519 - accuracy: 0.9342 - val_loss: 0.0805 - val_accuracy: 0.9811\n",
            "Epoch 179/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1471 - accuracy: 0.9373 - val_loss: 0.0854 - val_accuracy: 0.9787\n",
            "Epoch 180/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1416 - accuracy: 0.9397 - val_loss: 0.0792 - val_accuracy: 0.9815\n",
            "Epoch 181/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1424 - accuracy: 0.9397 - val_loss: 0.0832 - val_accuracy: 0.9786\n",
            "Epoch 182/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1455 - accuracy: 0.9381 - val_loss: 0.0847 - val_accuracy: 0.9817\n",
            "Epoch 183/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1443 - accuracy: 0.9384 - val_loss: 0.0793 - val_accuracy: 0.9810\n",
            "Epoch 184/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1426 - accuracy: 0.9390 - val_loss: 0.0832 - val_accuracy: 0.9801\n",
            "Epoch 185/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.1423 - accuracy: 0.9390 - val_loss: 0.0832 - val_accuracy: 0.9789\n",
            "Epoch 186/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1454 - accuracy: 0.9384 - val_loss: 0.0792 - val_accuracy: 0.9809\n",
            "Epoch 187/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1410 - accuracy: 0.9403 - val_loss: 0.0794 - val_accuracy: 0.9799\n",
            "Epoch 188/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1395 - accuracy: 0.9409 - val_loss: 0.0804 - val_accuracy: 0.9804\n",
            "Epoch 189/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1418 - accuracy: 0.9401 - val_loss: 0.0773 - val_accuracy: 0.9831\n",
            "Epoch 190/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1400 - accuracy: 0.9408 - val_loss: 0.0747 - val_accuracy: 0.9832\n",
            "Epoch 191/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1419 - accuracy: 0.9397 - val_loss: 0.0782 - val_accuracy: 0.9814\n",
            "Epoch 192/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1393 - accuracy: 0.9408 - val_loss: 0.0830 - val_accuracy: 0.9821\n",
            "Epoch 193/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1392 - accuracy: 0.9411 - val_loss: 0.0799 - val_accuracy: 0.9816\n",
            "Epoch 194/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1439 - accuracy: 0.9387 - val_loss: 0.0798 - val_accuracy: 0.9830\n",
            "Epoch 195/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1410 - accuracy: 0.9399 - val_loss: 0.0788 - val_accuracy: 0.9816\n",
            "Epoch 196/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1379 - accuracy: 0.9417 - val_loss: 0.0768 - val_accuracy: 0.9812\n",
            "Epoch 197/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1371 - accuracy: 0.9413 - val_loss: 0.0771 - val_accuracy: 0.9827\n",
            "Epoch 198/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1406 - accuracy: 0.9403 - val_loss: 0.0721 - val_accuracy: 0.9821\n",
            "Epoch 199/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1355 - accuracy: 0.9422 - val_loss: 0.0715 - val_accuracy: 0.9840\n",
            "Epoch 200/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1356 - accuracy: 0.9424 - val_loss: 0.0729 - val_accuracy: 0.9820\n",
            "Epoch 201/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1349 - accuracy: 0.9433 - val_loss: 0.0745 - val_accuracy: 0.9838\n",
            "Epoch 202/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1382 - accuracy: 0.9414 - val_loss: 0.0714 - val_accuracy: 0.9847\n",
            "Epoch 203/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1340 - accuracy: 0.9429 - val_loss: 0.0693 - val_accuracy: 0.9840\n",
            "Epoch 204/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1324 - accuracy: 0.9438 - val_loss: 0.0716 - val_accuracy: 0.9843\n",
            "Epoch 205/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1312 - accuracy: 0.9447 - val_loss: 0.0721 - val_accuracy: 0.9821\n",
            "Epoch 206/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1335 - accuracy: 0.9437 - val_loss: 0.0701 - val_accuracy: 0.9828\n",
            "Epoch 207/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1317 - accuracy: 0.9441 - val_loss: 0.0689 - val_accuracy: 0.9844\n",
            "Epoch 208/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1314 - accuracy: 0.9447 - val_loss: 0.0715 - val_accuracy: 0.9840\n",
            "Epoch 209/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1278 - accuracy: 0.9461 - val_loss: 0.0654 - val_accuracy: 0.9856\n",
            "Epoch 210/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1270 - accuracy: 0.9459 - val_loss: 0.0671 - val_accuracy: 0.9836\n",
            "Epoch 211/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1296 - accuracy: 0.9453 - val_loss: 0.0667 - val_accuracy: 0.9828\n",
            "Epoch 212/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1278 - accuracy: 0.9462 - val_loss: 0.0663 - val_accuracy: 0.9850\n",
            "Epoch 213/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1284 - accuracy: 0.9462 - val_loss: 0.0638 - val_accuracy: 0.9865\n",
            "Epoch 214/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1275 - accuracy: 0.9457 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
            "Epoch 215/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1262 - accuracy: 0.9466 - val_loss: 0.0694 - val_accuracy: 0.9849\n",
            "Epoch 216/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1265 - accuracy: 0.9462 - val_loss: 0.0667 - val_accuracy: 0.9849\n",
            "Epoch 217/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.1286 - accuracy: 0.9450 - val_loss: 0.0660 - val_accuracy: 0.9862\n",
            "Epoch 218/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1273 - accuracy: 0.9465 - val_loss: 0.0668 - val_accuracy: 0.9851\n",
            "Epoch 219/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.1262 - accuracy: 0.9467 - val_loss: 0.0676 - val_accuracy: 0.9859\n",
            "Epoch 220/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1262 - accuracy: 0.9465 - val_loss: 0.0662 - val_accuracy: 0.9845\n",
            "Epoch 221/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1254 - accuracy: 0.9466 - val_loss: 0.0630 - val_accuracy: 0.9862\n",
            "Epoch 222/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1262 - accuracy: 0.9478 - val_loss: 0.0657 - val_accuracy: 0.9857\n",
            "Epoch 223/500\n",
            "17577/17577 [==============================] - 2s 98us/step - loss: 0.1234 - accuracy: 0.9481 - val_loss: 0.0640 - val_accuracy: 0.9866\n",
            "Epoch 224/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1243 - accuracy: 0.9478 - val_loss: 0.0643 - val_accuracy: 0.9849\n",
            "Epoch 225/500\n",
            "17577/17577 [==============================] - 2s 100us/step - loss: 0.1239 - accuracy: 0.9471 - val_loss: 0.0588 - val_accuracy: 0.9864\n",
            "Epoch 226/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1259 - accuracy: 0.9467 - val_loss: 0.0631 - val_accuracy: 0.9866\n",
            "Epoch 227/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1194 - accuracy: 0.9504 - val_loss: 0.0621 - val_accuracy: 0.9863\n",
            "Epoch 228/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1261 - accuracy: 0.9463 - val_loss: 0.0584 - val_accuracy: 0.9875\n",
            "Epoch 229/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1234 - accuracy: 0.9485 - val_loss: 0.0589 - val_accuracy: 0.9875\n",
            "Epoch 230/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1216 - accuracy: 0.9489 - val_loss: 0.0595 - val_accuracy: 0.9870\n",
            "Epoch 231/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1197 - accuracy: 0.9501 - val_loss: 0.0594 - val_accuracy: 0.9861\n",
            "Epoch 232/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1202 - accuracy: 0.9493 - val_loss: 0.0620 - val_accuracy: 0.9862\n",
            "Epoch 233/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1172 - accuracy: 0.9509 - val_loss: 0.0590 - val_accuracy: 0.9881\n",
            "Epoch 234/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1202 - accuracy: 0.9493 - val_loss: 0.0591 - val_accuracy: 0.9868\n",
            "Epoch 235/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1197 - accuracy: 0.9500 - val_loss: 0.0590 - val_accuracy: 0.9875\n",
            "Epoch 236/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1192 - accuracy: 0.9496 - val_loss: 0.0608 - val_accuracy: 0.9870\n",
            "Epoch 237/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1185 - accuracy: 0.9505 - val_loss: 0.0566 - val_accuracy: 0.9876\n",
            "Epoch 238/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1178 - accuracy: 0.9508 - val_loss: 0.0539 - val_accuracy: 0.9868\n",
            "Epoch 239/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1183 - accuracy: 0.9497 - val_loss: 0.0543 - val_accuracy: 0.9884\n",
            "Epoch 240/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1168 - accuracy: 0.9508 - val_loss: 0.0556 - val_accuracy: 0.9876\n",
            "Epoch 241/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1169 - accuracy: 0.9504 - val_loss: 0.0557 - val_accuracy: 0.9880\n",
            "Epoch 242/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1157 - accuracy: 0.9514 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
            "Epoch 243/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1143 - accuracy: 0.9515 - val_loss: 0.0550 - val_accuracy: 0.9887\n",
            "Epoch 244/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1188 - accuracy: 0.9497 - val_loss: 0.0525 - val_accuracy: 0.9898\n",
            "Epoch 245/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1172 - accuracy: 0.9496 - val_loss: 0.0545 - val_accuracy: 0.9889\n",
            "Epoch 246/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1181 - accuracy: 0.9502 - val_loss: 0.0561 - val_accuracy: 0.9896\n",
            "Epoch 247/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1162 - accuracy: 0.9509 - val_loss: 0.0510 - val_accuracy: 0.9899\n",
            "Epoch 248/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.1184 - accuracy: 0.9499 - val_loss: 0.0526 - val_accuracy: 0.9885\n",
            "Epoch 249/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1168 - accuracy: 0.9505 - val_loss: 0.0524 - val_accuracy: 0.9882\n",
            "Epoch 250/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1178 - accuracy: 0.9507 - val_loss: 0.0521 - val_accuracy: 0.9897\n",
            "Epoch 251/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1146 - accuracy: 0.9521 - val_loss: 0.0522 - val_accuracy: 0.9892\n",
            "Epoch 252/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1123 - accuracy: 0.9532 - val_loss: 0.0519 - val_accuracy: 0.9896\n",
            "Epoch 253/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1102 - accuracy: 0.9537 - val_loss: 0.0516 - val_accuracy: 0.9896\n",
            "Epoch 254/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1102 - accuracy: 0.9539 - val_loss: 0.0499 - val_accuracy: 0.9905\n",
            "Epoch 255/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1116 - accuracy: 0.9539 - val_loss: 0.0526 - val_accuracy: 0.9896\n",
            "Epoch 256/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1111 - accuracy: 0.9531 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 257/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1119 - accuracy: 0.9531 - val_loss: 0.0524 - val_accuracy: 0.9889\n",
            "Epoch 258/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1099 - accuracy: 0.9538 - val_loss: 0.0557 - val_accuracy: 0.9882\n",
            "Epoch 259/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1171 - accuracy: 0.9509 - val_loss: 0.0552 - val_accuracy: 0.9883\n",
            "Epoch 260/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1122 - accuracy: 0.9531 - val_loss: 0.0586 - val_accuracy: 0.9885\n",
            "Epoch 261/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1109 - accuracy: 0.9538 - val_loss: 0.0513 - val_accuracy: 0.9895\n",
            "Epoch 262/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1129 - accuracy: 0.9528 - val_loss: 0.0501 - val_accuracy: 0.9909\n",
            "Epoch 263/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1118 - accuracy: 0.9525 - val_loss: 0.0523 - val_accuracy: 0.9884\n",
            "Epoch 264/500\n",
            "17577/17577 [==============================] - 2s 98us/step - loss: 0.1107 - accuracy: 0.9534 - val_loss: 0.0491 - val_accuracy: 0.9904\n",
            "Epoch 265/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1055 - accuracy: 0.9563 - val_loss: 0.0491 - val_accuracy: 0.9903\n",
            "Epoch 266/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1097 - accuracy: 0.9537 - val_loss: 0.0507 - val_accuracy: 0.9893\n",
            "Epoch 267/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.1087 - accuracy: 0.9541 - val_loss: 0.0509 - val_accuracy: 0.9904\n",
            "Epoch 268/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1103 - accuracy: 0.9545 - val_loss: 0.0484 - val_accuracy: 0.9908\n",
            "Epoch 269/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1100 - accuracy: 0.9539 - val_loss: 0.0459 - val_accuracy: 0.9908\n",
            "Epoch 270/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.1100 - accuracy: 0.9541 - val_loss: 0.0488 - val_accuracy: 0.9898\n",
            "Epoch 271/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1072 - accuracy: 0.9551 - val_loss: 0.0475 - val_accuracy: 0.9902\n",
            "Epoch 272/500\n",
            "17577/17577 [==============================] - 2s 98us/step - loss: 0.1105 - accuracy: 0.9535 - val_loss: 0.0462 - val_accuracy: 0.9903\n",
            "Epoch 273/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1094 - accuracy: 0.9542 - val_loss: 0.0478 - val_accuracy: 0.9906\n",
            "Epoch 274/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1080 - accuracy: 0.9545 - val_loss: 0.0468 - val_accuracy: 0.9895\n",
            "Epoch 275/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1083 - accuracy: 0.9549 - val_loss: 0.0465 - val_accuracy: 0.9920\n",
            "Epoch 276/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1076 - accuracy: 0.9553 - val_loss: 0.0466 - val_accuracy: 0.9916\n",
            "Epoch 277/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1074 - accuracy: 0.9547 - val_loss: 0.0473 - val_accuracy: 0.9913\n",
            "Epoch 278/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1075 - accuracy: 0.9547 - val_loss: 0.0460 - val_accuracy: 0.9910\n",
            "Epoch 279/500\n",
            "17577/17577 [==============================] - 2s 98us/step - loss: 0.1062 - accuracy: 0.9553 - val_loss: 0.0460 - val_accuracy: 0.9912\n",
            "Epoch 280/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1065 - accuracy: 0.9555 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
            "Epoch 281/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1028 - accuracy: 0.9572 - val_loss: 0.0449 - val_accuracy: 0.9910\n",
            "Epoch 282/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1034 - accuracy: 0.9571 - val_loss: 0.0475 - val_accuracy: 0.9901\n",
            "Epoch 283/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1066 - accuracy: 0.9555 - val_loss: 0.0456 - val_accuracy: 0.9902\n",
            "Epoch 284/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1075 - accuracy: 0.9551 - val_loss: 0.0455 - val_accuracy: 0.9907\n",
            "Epoch 285/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1073 - accuracy: 0.9543 - val_loss: 0.0430 - val_accuracy: 0.9911\n",
            "Epoch 286/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.1040 - accuracy: 0.9565 - val_loss: 0.0433 - val_accuracy: 0.9913\n",
            "Epoch 287/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.1050 - accuracy: 0.9561 - val_loss: 0.0428 - val_accuracy: 0.9913\n",
            "Epoch 288/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1074 - accuracy: 0.9545 - val_loss: 0.0468 - val_accuracy: 0.9912\n",
            "Epoch 289/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1060 - accuracy: 0.9552 - val_loss: 0.0461 - val_accuracy: 0.9915\n",
            "Epoch 290/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1046 - accuracy: 0.9566 - val_loss: 0.0431 - val_accuracy: 0.9920\n",
            "Epoch 291/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.1016 - accuracy: 0.9571 - val_loss: 0.0425 - val_accuracy: 0.9923\n",
            "Epoch 292/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1020 - accuracy: 0.9581 - val_loss: 0.0485 - val_accuracy: 0.9901\n",
            "Epoch 293/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1039 - accuracy: 0.9568 - val_loss: 0.0431 - val_accuracy: 0.9921\n",
            "Epoch 294/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.1028 - accuracy: 0.9572 - val_loss: 0.0426 - val_accuracy: 0.9916\n",
            "Epoch 295/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0990 - accuracy: 0.9587 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
            "Epoch 296/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.1028 - accuracy: 0.9568 - val_loss: 0.0442 - val_accuracy: 0.9913\n",
            "Epoch 297/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.1024 - accuracy: 0.9569 - val_loss: 0.0442 - val_accuracy: 0.9906\n",
            "Epoch 298/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1039 - accuracy: 0.9566 - val_loss: 0.0475 - val_accuracy: 0.9906\n",
            "Epoch 299/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1013 - accuracy: 0.9582 - val_loss: 0.0436 - val_accuracy: 0.9917\n",
            "Epoch 300/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.1011 - accuracy: 0.9576 - val_loss: 0.0470 - val_accuracy: 0.9920\n",
            "Epoch 301/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.1037 - accuracy: 0.9563 - val_loss: 0.0449 - val_accuracy: 0.9927\n",
            "Epoch 302/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1028 - accuracy: 0.9571 - val_loss: 0.0419 - val_accuracy: 0.9918\n",
            "Epoch 303/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1028 - accuracy: 0.9570 - val_loss: 0.0436 - val_accuracy: 0.9918\n",
            "Epoch 304/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0983 - accuracy: 0.9590 - val_loss: 0.0411 - val_accuracy: 0.9925\n",
            "Epoch 305/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0991 - accuracy: 0.9589 - val_loss: 0.0415 - val_accuracy: 0.9933\n",
            "Epoch 306/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.1012 - accuracy: 0.9578 - val_loss: 0.0410 - val_accuracy: 0.9922\n",
            "Epoch 307/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1013 - accuracy: 0.9572 - val_loss: 0.0408 - val_accuracy: 0.9925\n",
            "Epoch 308/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1045 - accuracy: 0.9558 - val_loss: 0.0430 - val_accuracy: 0.9929\n",
            "Epoch 309/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.0994 - accuracy: 0.9587 - val_loss: 0.0427 - val_accuracy: 0.9931\n",
            "Epoch 310/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0996 - accuracy: 0.9581 - val_loss: 0.0429 - val_accuracy: 0.9928\n",
            "Epoch 311/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.0958 - accuracy: 0.9602 - val_loss: 0.0413 - val_accuracy: 0.9933\n",
            "Epoch 312/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0975 - accuracy: 0.9590 - val_loss: 0.0381 - val_accuracy: 0.9925\n",
            "Epoch 313/500\n",
            "17577/17577 [==============================] - 2s 105us/step - loss: 0.0997 - accuracy: 0.9585 - val_loss: 0.0405 - val_accuracy: 0.9927\n",
            "Epoch 314/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0981 - accuracy: 0.9592 - val_loss: 0.0386 - val_accuracy: 0.9930\n",
            "Epoch 315/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.0975 - accuracy: 0.9585 - val_loss: 0.0372 - val_accuracy: 0.9933\n",
            "Epoch 316/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0945 - accuracy: 0.9602 - val_loss: 0.0387 - val_accuracy: 0.9928\n",
            "Epoch 317/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.1003 - accuracy: 0.9577 - val_loss: 0.0383 - val_accuracy: 0.9930\n",
            "Epoch 318/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0986 - accuracy: 0.9589 - val_loss: 0.0407 - val_accuracy: 0.9923\n",
            "Epoch 319/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0972 - accuracy: 0.9595 - val_loss: 0.0375 - val_accuracy: 0.9930\n",
            "Epoch 320/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0973 - accuracy: 0.9595 - val_loss: 0.0385 - val_accuracy: 0.9924\n",
            "Epoch 321/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.0990 - accuracy: 0.9588 - val_loss: 0.0391 - val_accuracy: 0.9927\n",
            "Epoch 322/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0969 - accuracy: 0.9595 - val_loss: 0.0380 - val_accuracy: 0.9930\n",
            "Epoch 323/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.1002 - accuracy: 0.9583 - val_loss: 0.0411 - val_accuracy: 0.9915\n",
            "Epoch 324/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0983 - accuracy: 0.9586 - val_loss: 0.0381 - val_accuracy: 0.9932\n",
            "Epoch 325/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0974 - accuracy: 0.9588 - val_loss: 0.0396 - val_accuracy: 0.9922\n",
            "Epoch 326/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0955 - accuracy: 0.9606 - val_loss: 0.0400 - val_accuracy: 0.9920\n",
            "Epoch 327/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0979 - accuracy: 0.9586 - val_loss: 0.0378 - val_accuracy: 0.9922\n",
            "Epoch 328/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0957 - accuracy: 0.9604 - val_loss: 0.0367 - val_accuracy: 0.9930\n",
            "Epoch 329/500\n",
            "17577/17577 [==============================] - 2s 99us/step - loss: 0.0931 - accuracy: 0.9613 - val_loss: 0.0377 - val_accuracy: 0.9922\n",
            "Epoch 330/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0942 - accuracy: 0.9612 - val_loss: 0.0392 - val_accuracy: 0.9926\n",
            "Epoch 331/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0949 - accuracy: 0.9604 - val_loss: 0.0377 - val_accuracy: 0.9924\n",
            "Epoch 332/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0932 - accuracy: 0.9614 - val_loss: 0.0381 - val_accuracy: 0.9925\n",
            "Epoch 333/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0942 - accuracy: 0.9611 - val_loss: 0.0392 - val_accuracy: 0.9927\n",
            "Epoch 334/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0937 - accuracy: 0.9609 - val_loss: 0.0353 - val_accuracy: 0.9922\n",
            "Epoch 335/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0908 - accuracy: 0.9623 - val_loss: 0.0367 - val_accuracy: 0.9922\n",
            "Epoch 336/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0938 - accuracy: 0.9608 - val_loss: 0.0357 - val_accuracy: 0.9934\n",
            "Epoch 337/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0946 - accuracy: 0.9607 - val_loss: 0.0342 - val_accuracy: 0.9934\n",
            "Epoch 338/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0936 - accuracy: 0.9612 - val_loss: 0.0372 - val_accuracy: 0.9923\n",
            "Epoch 339/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0925 - accuracy: 0.9623 - val_loss: 0.0356 - val_accuracy: 0.9934\n",
            "Epoch 340/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0912 - accuracy: 0.9624 - val_loss: 0.0360 - val_accuracy: 0.9923\n",
            "Epoch 341/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0960 - accuracy: 0.9597 - val_loss: 0.0356 - val_accuracy: 0.9932\n",
            "Epoch 342/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0922 - accuracy: 0.9612 - val_loss: 0.0356 - val_accuracy: 0.9938\n",
            "Epoch 343/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0948 - accuracy: 0.9610 - val_loss: 0.0353 - val_accuracy: 0.9927\n",
            "Epoch 344/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0910 - accuracy: 0.9621 - val_loss: 0.0370 - val_accuracy: 0.9933\n",
            "Epoch 345/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0917 - accuracy: 0.9617 - val_loss: 0.0357 - val_accuracy: 0.9928\n",
            "Epoch 346/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0912 - accuracy: 0.9621 - val_loss: 0.0358 - val_accuracy: 0.9933\n",
            "Epoch 347/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0918 - accuracy: 0.9621 - val_loss: 0.0355 - val_accuracy: 0.9935\n",
            "Epoch 348/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0908 - accuracy: 0.9622 - val_loss: 0.0346 - val_accuracy: 0.9938\n",
            "Epoch 349/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0909 - accuracy: 0.9620 - val_loss: 0.0354 - val_accuracy: 0.9931\n",
            "Epoch 350/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0922 - accuracy: 0.9616 - val_loss: 0.0347 - val_accuracy: 0.9939\n",
            "Epoch 351/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0909 - accuracy: 0.9622 - val_loss: 0.0345 - val_accuracy: 0.9926\n",
            "Epoch 352/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.0930 - accuracy: 0.9617 - val_loss: 0.0345 - val_accuracy: 0.9923\n",
            "Epoch 353/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0892 - accuracy: 0.9627 - val_loss: 0.0346 - val_accuracy: 0.9940\n",
            "Epoch 354/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0896 - accuracy: 0.9630 - val_loss: 0.0341 - val_accuracy: 0.9933\n",
            "Epoch 355/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.0917 - accuracy: 0.9615 - val_loss: 0.0321 - val_accuracy: 0.9943\n",
            "Epoch 356/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0918 - accuracy: 0.9623 - val_loss: 0.0332 - val_accuracy: 0.9939\n",
            "Epoch 357/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0908 - accuracy: 0.9623 - val_loss: 0.0343 - val_accuracy: 0.9941\n",
            "Epoch 358/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0882 - accuracy: 0.9631 - val_loss: 0.0350 - val_accuracy: 0.9936\n",
            "Epoch 359/500\n",
            "17577/17577 [==============================] - 2s 98us/step - loss: 0.0924 - accuracy: 0.9616 - val_loss: 0.0353 - val_accuracy: 0.9941\n",
            "Epoch 360/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0893 - accuracy: 0.9625 - val_loss: 0.0346 - val_accuracy: 0.9933\n",
            "Epoch 361/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0899 - accuracy: 0.9628 - val_loss: 0.0332 - val_accuracy: 0.9939\n",
            "Epoch 362/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0898 - accuracy: 0.9629 - val_loss: 0.0350 - val_accuracy: 0.9938\n",
            "Epoch 363/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0896 - accuracy: 0.9632 - val_loss: 0.0348 - val_accuracy: 0.9942\n",
            "Epoch 364/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0921 - accuracy: 0.9622 - val_loss: 0.0336 - val_accuracy: 0.9949\n",
            "Epoch 365/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0893 - accuracy: 0.9633 - val_loss: 0.0348 - val_accuracy: 0.9934\n",
            "Epoch 366/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.0908 - accuracy: 0.9620 - val_loss: 0.0338 - val_accuracy: 0.9940\n",
            "Epoch 367/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0907 - accuracy: 0.9622 - val_loss: 0.0322 - val_accuracy: 0.9933\n",
            "Epoch 368/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0890 - accuracy: 0.9632 - val_loss: 0.0309 - val_accuracy: 0.9928\n",
            "Epoch 369/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0876 - accuracy: 0.9636 - val_loss: 0.0332 - val_accuracy: 0.9937\n",
            "Epoch 370/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.0888 - accuracy: 0.9631 - val_loss: 0.0319 - val_accuracy: 0.9935\n",
            "Epoch 371/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0891 - accuracy: 0.9632 - val_loss: 0.0310 - val_accuracy: 0.9934\n",
            "Epoch 372/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0904 - accuracy: 0.9622 - val_loss: 0.0302 - val_accuracy: 0.9940\n",
            "Epoch 373/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0893 - accuracy: 0.9630 - val_loss: 0.0323 - val_accuracy: 0.9939\n",
            "Epoch 374/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0882 - accuracy: 0.9632 - val_loss: 0.0331 - val_accuracy: 0.9937\n",
            "Epoch 375/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0880 - accuracy: 0.9632 - val_loss: 0.0323 - val_accuracy: 0.9939\n",
            "Epoch 376/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0923 - accuracy: 0.9621 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
            "Epoch 377/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0883 - accuracy: 0.9633 - val_loss: 0.0331 - val_accuracy: 0.9941\n",
            "Epoch 378/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0865 - accuracy: 0.9644 - val_loss: 0.0300 - val_accuracy: 0.9943\n",
            "Epoch 379/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0893 - accuracy: 0.9633 - val_loss: 0.0321 - val_accuracy: 0.9940\n",
            "Epoch 380/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0879 - accuracy: 0.9634 - val_loss: 0.0303 - val_accuracy: 0.9946\n",
            "Epoch 381/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.0897 - accuracy: 0.9627 - val_loss: 0.0322 - val_accuracy: 0.9936\n",
            "Epoch 382/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0874 - accuracy: 0.9642 - val_loss: 0.0312 - val_accuracy: 0.9936\n",
            "Epoch 383/500\n",
            "17577/17577 [==============================] - 2s 95us/step - loss: 0.0860 - accuracy: 0.9639 - val_loss: 0.0316 - val_accuracy: 0.9938\n",
            "Epoch 384/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0850 - accuracy: 0.9648 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
            "Epoch 385/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0876 - accuracy: 0.9636 - val_loss: 0.0311 - val_accuracy: 0.9943\n",
            "Epoch 386/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0868 - accuracy: 0.9645 - val_loss: 0.0301 - val_accuracy: 0.9942\n",
            "Epoch 387/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0860 - accuracy: 0.9639 - val_loss: 0.0302 - val_accuracy: 0.9943\n",
            "Epoch 388/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0885 - accuracy: 0.9636 - val_loss: 0.0301 - val_accuracy: 0.9942\n",
            "Epoch 389/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.0879 - accuracy: 0.9636 - val_loss: 0.0291 - val_accuracy: 0.9947\n",
            "Epoch 390/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0853 - accuracy: 0.9645 - val_loss: 0.0291 - val_accuracy: 0.9947\n",
            "Epoch 391/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0840 - accuracy: 0.9647 - val_loss: 0.0319 - val_accuracy: 0.9937\n",
            "Epoch 392/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0847 - accuracy: 0.9653 - val_loss: 0.0289 - val_accuracy: 0.9946\n",
            "Epoch 393/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0859 - accuracy: 0.9642 - val_loss: 0.0278 - val_accuracy: 0.9953\n",
            "Epoch 394/500\n",
            "17577/17577 [==============================] - 2s 100us/step - loss: 0.0833 - accuracy: 0.9655 - val_loss: 0.0298 - val_accuracy: 0.9947\n",
            "Epoch 395/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.0832 - accuracy: 0.9654 - val_loss: 0.0291 - val_accuracy: 0.9941\n",
            "Epoch 396/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0857 - accuracy: 0.9652 - val_loss: 0.0310 - val_accuracy: 0.9944\n",
            "Epoch 397/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.0829 - accuracy: 0.9654 - val_loss: 0.0298 - val_accuracy: 0.9944\n",
            "Epoch 398/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0843 - accuracy: 0.9653 - val_loss: 0.0296 - val_accuracy: 0.9943\n",
            "Epoch 399/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0846 - accuracy: 0.9648 - val_loss: 0.0285 - val_accuracy: 0.9948\n",
            "Epoch 400/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0821 - accuracy: 0.9663 - val_loss: 0.0296 - val_accuracy: 0.9945\n",
            "Epoch 401/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0833 - accuracy: 0.9654 - val_loss: 0.0295 - val_accuracy: 0.9946\n",
            "Epoch 402/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0849 - accuracy: 0.9648 - val_loss: 0.0292 - val_accuracy: 0.9945\n",
            "Epoch 403/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0856 - accuracy: 0.9650 - val_loss: 0.0296 - val_accuracy: 0.9944\n",
            "Epoch 404/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0840 - accuracy: 0.9649 - val_loss: 0.0272 - val_accuracy: 0.9949\n",
            "Epoch 405/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0843 - accuracy: 0.9649 - val_loss: 0.0300 - val_accuracy: 0.9938\n",
            "Epoch 406/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0837 - accuracy: 0.9655 - val_loss: 0.0290 - val_accuracy: 0.9948\n",
            "Epoch 407/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0827 - accuracy: 0.9653 - val_loss: 0.0281 - val_accuracy: 0.9953\n",
            "Epoch 408/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0836 - accuracy: 0.9654 - val_loss: 0.0284 - val_accuracy: 0.9944\n",
            "Epoch 409/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0845 - accuracy: 0.9651 - val_loss: 0.0265 - val_accuracy: 0.9950\n",
            "Epoch 410/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0824 - accuracy: 0.9663 - val_loss: 0.0283 - val_accuracy: 0.9939\n",
            "Epoch 411/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0824 - accuracy: 0.9661 - val_loss: 0.0271 - val_accuracy: 0.9952\n",
            "Epoch 412/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0824 - accuracy: 0.9660 - val_loss: 0.0272 - val_accuracy: 0.9950\n",
            "Epoch 413/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0828 - accuracy: 0.9658 - val_loss: 0.0262 - val_accuracy: 0.9959\n",
            "Epoch 414/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0838 - accuracy: 0.9657 - val_loss: 0.0276 - val_accuracy: 0.9955\n",
            "Epoch 415/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0809 - accuracy: 0.9668 - val_loss: 0.0275 - val_accuracy: 0.9947\n",
            "Epoch 416/500\n",
            "17577/17577 [==============================] - 2s 101us/step - loss: 0.0820 - accuracy: 0.9661 - val_loss: 0.0269 - val_accuracy: 0.9953\n",
            "Epoch 417/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0841 - accuracy: 0.9651 - val_loss: 0.0278 - val_accuracy: 0.9949\n",
            "Epoch 418/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0817 - accuracy: 0.9663 - val_loss: 0.0264 - val_accuracy: 0.9954\n",
            "Epoch 419/500\n",
            "17577/17577 [==============================] - 2s 97us/step - loss: 0.0828 - accuracy: 0.9654 - val_loss: 0.0268 - val_accuracy: 0.9947\n",
            "Epoch 420/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0822 - accuracy: 0.9662 - val_loss: 0.0270 - val_accuracy: 0.9951\n",
            "Epoch 421/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0795 - accuracy: 0.9670 - val_loss: 0.0273 - val_accuracy: 0.9941\n",
            "Epoch 422/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0805 - accuracy: 0.9661 - val_loss: 0.0272 - val_accuracy: 0.9950\n",
            "Epoch 423/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0813 - accuracy: 0.9667 - val_loss: 0.0274 - val_accuracy: 0.9950\n",
            "Epoch 424/500\n",
            "17577/17577 [==============================] - 1s 85us/step - loss: 0.0820 - accuracy: 0.9663 - val_loss: 0.0298 - val_accuracy: 0.9936\n",
            "Epoch 425/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.0833 - accuracy: 0.9656 - val_loss: 0.0279 - val_accuracy: 0.9949\n",
            "Epoch 426/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0846 - accuracy: 0.9646 - val_loss: 0.0265 - val_accuracy: 0.9950\n",
            "Epoch 427/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0820 - accuracy: 0.9659 - val_loss: 0.0273 - val_accuracy: 0.9949\n",
            "Epoch 428/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0812 - accuracy: 0.9666 - val_loss: 0.0271 - val_accuracy: 0.9953\n",
            "Epoch 429/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0794 - accuracy: 0.9676 - val_loss: 0.0275 - val_accuracy: 0.9954\n",
            "Epoch 430/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.0813 - accuracy: 0.9656 - val_loss: 0.0276 - val_accuracy: 0.9947\n",
            "Epoch 431/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0791 - accuracy: 0.9670 - val_loss: 0.0253 - val_accuracy: 0.9953\n",
            "Epoch 432/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0809 - accuracy: 0.9670 - val_loss: 0.0282 - val_accuracy: 0.9939\n",
            "Epoch 433/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0809 - accuracy: 0.9664 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
            "Epoch 434/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0791 - accuracy: 0.9674 - val_loss: 0.0254 - val_accuracy: 0.9950\n",
            "Epoch 435/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0796 - accuracy: 0.9674 - val_loss: 0.0252 - val_accuracy: 0.9953\n",
            "Epoch 436/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0793 - accuracy: 0.9670 - val_loss: 0.0258 - val_accuracy: 0.9955\n",
            "Epoch 437/500\n",
            "17577/17577 [==============================] - 2s 96us/step - loss: 0.0802 - accuracy: 0.9672 - val_loss: 0.0250 - val_accuracy: 0.9957\n",
            "Epoch 438/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0797 - accuracy: 0.9675 - val_loss: 0.0268 - val_accuracy: 0.9959\n",
            "Epoch 439/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0788 - accuracy: 0.9683 - val_loss: 0.0258 - val_accuracy: 0.9958\n",
            "Epoch 440/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0811 - accuracy: 0.9667 - val_loss: 0.0248 - val_accuracy: 0.9960\n",
            "Epoch 441/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0814 - accuracy: 0.9661 - val_loss: 0.0241 - val_accuracy: 0.9953\n",
            "Epoch 442/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0785 - accuracy: 0.9678 - val_loss: 0.0258 - val_accuracy: 0.9951\n",
            "Epoch 443/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0803 - accuracy: 0.9663 - val_loss: 0.0261 - val_accuracy: 0.9954\n",
            "Epoch 444/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0787 - accuracy: 0.9673 - val_loss: 0.0248 - val_accuracy: 0.9961\n",
            "Epoch 445/500\n",
            "17577/17577 [==============================] - 2s 102us/step - loss: 0.0791 - accuracy: 0.9675 - val_loss: 0.0251 - val_accuracy: 0.9959\n",
            "Epoch 446/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0786 - accuracy: 0.9678 - val_loss: 0.0241 - val_accuracy: 0.9955\n",
            "Epoch 447/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0800 - accuracy: 0.9666 - val_loss: 0.0231 - val_accuracy: 0.9962\n",
            "Epoch 448/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0792 - accuracy: 0.9672 - val_loss: 0.0236 - val_accuracy: 0.9956\n",
            "Epoch 449/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0798 - accuracy: 0.9673 - val_loss: 0.0218 - val_accuracy: 0.9965\n",
            "Epoch 450/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0793 - accuracy: 0.9676 - val_loss: 0.0244 - val_accuracy: 0.9957\n",
            "Epoch 451/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0786 - accuracy: 0.9670 - val_loss: 0.0249 - val_accuracy: 0.9960\n",
            "Epoch 452/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.0780 - accuracy: 0.9675 - val_loss: 0.0233 - val_accuracy: 0.9961\n",
            "Epoch 453/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0774 - accuracy: 0.9687 - val_loss: 0.0249 - val_accuracy: 0.9959\n",
            "Epoch 454/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0774 - accuracy: 0.9678 - val_loss: 0.0234 - val_accuracy: 0.9958\n",
            "Epoch 455/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0784 - accuracy: 0.9676 - val_loss: 0.0239 - val_accuracy: 0.9964\n",
            "Epoch 456/500\n",
            "17577/17577 [==============================] - 2s 92us/step - loss: 0.0766 - accuracy: 0.9692 - val_loss: 0.0242 - val_accuracy: 0.9961\n",
            "Epoch 457/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0778 - accuracy: 0.9679 - val_loss: 0.0251 - val_accuracy: 0.9951\n",
            "Epoch 458/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0780 - accuracy: 0.9682 - val_loss: 0.0247 - val_accuracy: 0.9955\n",
            "Epoch 459/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0784 - accuracy: 0.9678 - val_loss: 0.0240 - val_accuracy: 0.9959\n",
            "Epoch 460/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0766 - accuracy: 0.9686 - val_loss: 0.0250 - val_accuracy: 0.9963\n",
            "Epoch 461/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0776 - accuracy: 0.9680 - val_loss: 0.0244 - val_accuracy: 0.9956\n",
            "Epoch 462/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0749 - accuracy: 0.9695 - val_loss: 0.0251 - val_accuracy: 0.9951\n",
            "Epoch 463/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0773 - accuracy: 0.9683 - val_loss: 0.0227 - val_accuracy: 0.9960\n",
            "Epoch 464/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0780 - accuracy: 0.9677 - val_loss: 0.0219 - val_accuracy: 0.9961\n",
            "Epoch 465/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0783 - accuracy: 0.9679 - val_loss: 0.0237 - val_accuracy: 0.9951\n",
            "Epoch 466/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0801 - accuracy: 0.9672 - val_loss: 0.0235 - val_accuracy: 0.9956\n",
            "Epoch 467/500\n",
            "17577/17577 [==============================] - 2s 94us/step - loss: 0.0787 - accuracy: 0.9670 - val_loss: 0.0236 - val_accuracy: 0.9961\n",
            "Epoch 468/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0782 - accuracy: 0.9674 - val_loss: 0.0232 - val_accuracy: 0.9958\n",
            "Epoch 469/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0759 - accuracy: 0.9686 - val_loss: 0.0244 - val_accuracy: 0.9953\n",
            "Epoch 470/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0761 - accuracy: 0.9687 - val_loss: 0.0228 - val_accuracy: 0.9963\n",
            "Epoch 471/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0777 - accuracy: 0.9677 - val_loss: 0.0236 - val_accuracy: 0.9959\n",
            "Epoch 472/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0778 - accuracy: 0.9681 - val_loss: 0.0220 - val_accuracy: 0.9967\n",
            "Epoch 473/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0768 - accuracy: 0.9682 - val_loss: 0.0224 - val_accuracy: 0.9966\n",
            "Epoch 474/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0757 - accuracy: 0.9685 - val_loss: 0.0230 - val_accuracy: 0.9960\n",
            "Epoch 475/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0768 - accuracy: 0.9683 - val_loss: 0.0233 - val_accuracy: 0.9960\n",
            "Epoch 476/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0733 - accuracy: 0.9695 - val_loss: 0.0229 - val_accuracy: 0.9959\n",
            "Epoch 477/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0751 - accuracy: 0.9694 - val_loss: 0.0229 - val_accuracy: 0.9960\n",
            "Epoch 478/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0801 - accuracy: 0.9668 - val_loss: 0.0236 - val_accuracy: 0.9953\n",
            "Epoch 479/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0758 - accuracy: 0.9686 - val_loss: 0.0233 - val_accuracy: 0.9958\n",
            "Epoch 480/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0775 - accuracy: 0.9682 - val_loss: 0.0220 - val_accuracy: 0.9960\n",
            "Epoch 481/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0723 - accuracy: 0.9706 - val_loss: 0.0222 - val_accuracy: 0.9958\n",
            "Epoch 482/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0768 - accuracy: 0.9686 - val_loss: 0.0225 - val_accuracy: 0.9954\n",
            "Epoch 483/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0754 - accuracy: 0.9687 - val_loss: 0.0219 - val_accuracy: 0.9958\n",
            "Epoch 484/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0755 - accuracy: 0.9689 - val_loss: 0.0226 - val_accuracy: 0.9956\n",
            "Epoch 485/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0750 - accuracy: 0.9691 - val_loss: 0.0224 - val_accuracy: 0.9958\n",
            "Epoch 486/500\n",
            "17577/17577 [==============================] - 2s 87us/step - loss: 0.0754 - accuracy: 0.9683 - val_loss: 0.0224 - val_accuracy: 0.9961\n",
            "Epoch 487/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0769 - accuracy: 0.9683 - val_loss: 0.0224 - val_accuracy: 0.9952\n",
            "Epoch 488/500\n",
            "17577/17577 [==============================] - 2s 91us/step - loss: 0.0779 - accuracy: 0.9677 - val_loss: 0.0225 - val_accuracy: 0.9958\n",
            "Epoch 489/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0765 - accuracy: 0.9677 - val_loss: 0.0217 - val_accuracy: 0.9955\n",
            "Epoch 490/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0758 - accuracy: 0.9693 - val_loss: 0.0227 - val_accuracy: 0.9962\n",
            "Epoch 491/500\n",
            "17577/17577 [==============================] - 2s 101us/step - loss: 0.0727 - accuracy: 0.9698 - val_loss: 0.0207 - val_accuracy: 0.9966\n",
            "Epoch 492/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0723 - accuracy: 0.9702 - val_loss: 0.0229 - val_accuracy: 0.9955\n",
            "Epoch 493/500\n",
            "17577/17577 [==============================] - 2s 88us/step - loss: 0.0763 - accuracy: 0.9685 - val_loss: 0.0221 - val_accuracy: 0.9958\n",
            "Epoch 494/500\n",
            "17577/17577 [==============================] - 2s 90us/step - loss: 0.0735 - accuracy: 0.9700 - val_loss: 0.0240 - val_accuracy: 0.9955\n",
            "Epoch 495/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0768 - accuracy: 0.9684 - val_loss: 0.0211 - val_accuracy: 0.9963\n",
            "Epoch 496/500\n",
            "17577/17577 [==============================] - 2s 93us/step - loss: 0.0742 - accuracy: 0.9694 - val_loss: 0.0219 - val_accuracy: 0.9964\n",
            "Epoch 497/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0750 - accuracy: 0.9693 - val_loss: 0.0232 - val_accuracy: 0.9964\n",
            "Epoch 498/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0738 - accuracy: 0.9693 - val_loss: 0.0234 - val_accuracy: 0.9952\n",
            "Epoch 499/500\n",
            "17577/17577 [==============================] - 2s 86us/step - loss: 0.0724 - accuracy: 0.9708 - val_loss: 0.0235 - val_accuracy: 0.9958\n",
            "Epoch 500/500\n",
            "17577/17577 [==============================] - 2s 89us/step - loss: 0.0738 - accuracy: 0.9697 - val_loss: 0.0229 - val_accuracy: 0.9957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fls0-smNlDOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "cd27749b-251c-4610-c7d1-e68b756f60f1"
      },
      "source": [
        "tr_epochs = len(history.history['loss'])\n",
        "\n",
        "plt.plot(range(tr_epochs), history.history['loss'], label=\"loss\")\n",
        "plt.plot(range(tr_epochs), history.history['val_loss'], label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38xk1stHmp8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f9de643c-54dc-4b58-f516-5ea62997b8b6"
      },
      "source": [
        "tr_epochs = len(history.history['accuracy'])\n",
        "\n",
        "plt.plot(range(tr_epochs), history.history['accuracy'], label=\"accuracy\")\n",
        "plt.plot(range(tr_epochs), history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOvEfTJ3YFgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c42dd92b-a086-412b-b824-fe4867710721"
      },
      "source": [
        "argmax_acc = np.argmax(history.history['val_accuracy'])\n",
        "print('Val loss:{}\\tVal acc:{}'.format(history.history['val_loss'][argmax_acc], history.history['val_accuracy'][argmax_acc]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val loss:0.022005667675612864\tVal acc:0.9967292547225952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOM1GEHGYo-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model(\n",
        "    MODEL_FILE, \n",
        "    custom_objects={\n",
        "        'PREDICTIONS': PREDICTIONS\n",
        "      }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meyAymovazAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZHtDqL1bH-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8202505f-0ff9-4e06-bcb8-25aaf77437b2"
      },
      "source": [
        "assert(y_pred.shape == y_test.shape)\n",
        "\n",
        "y_test_ = y_test[:1500]\n",
        "y_pred_ = y_pred[:1500]\n",
        "\n",
        "plt.scatter([i for i in range(y_test_.shape[0] * y_test_.shape[1])], y_test_.flatten(), label=\"true values\")\n",
        "plt.scatter([i for i in range(y_pred_.shape[0] * y_pred_.shape[1])], np.round(y_pred_.flatten()), label=\"pred values\")\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA-TC6AE-SN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2eb76590-195b-4deb-8d54-a809dd04324d"
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test.flatten(), np.round(y_pred.flatten()), labels=[0, 1]).ravel()\n",
        "print('True negatives:{}\\tFalse positives:{}\\tFalse negatives:{}\\tTrue positive:{}'.format(tn, fp, fn, tp))\n",
        "print('Accuracy:{}'.format((tn + tp) / (tn + fp + fn + tp)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True negatives:26180\tFalse positives:74\tFalse negatives:89\tTrue positive:17601\n",
            "Accuracy:0.9962907336610232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv0fyO06UW_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2e4da4b9-164f-4a8e-f53d-6acf538a001a"
      },
      "source": [
        "print('Precision CLOSED:{}'.format(tp/(tp+fp)))\n",
        "print('Recall CLOSED:{}'.format(tp/(tp+fn)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision CLOSED:0.9958132956152758\n",
            "Recall CLOSED:0.9949689089881288\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}